{"nbformat_minor": 2, "cells": [{"execution_count": 1, "cell_type": "code", "source": "spark", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>398</td><td>application_1524108459514_0043</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-rubico.axklap43xjae3m2ddppk3oq4gb.ix.internal.cloudapp.net:8088/proxy/application_1524108459514_0043/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.13:30060/node/containerlogs/container_e60_1524108459514_0043_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n<pyspark.sql.session.SparkSession object at 0x7fb372ee1860>"}], "metadata": {"scrolled": true, "collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": "from pyspark.sql.functions import udf, array, col\nfrom pyspark.sql.types import StringType, StructType, StructField\nfrom pyspark.sql.utils import AnalysisException\n\nimport pandas as pd\n\n# configure the runid range to get more data start_id min is 100763\nstart_id = 100810\nend_id = 100817\n# Gives line count of dates for f_rk_transaction, f_rk_transaction_detail, f_rk_transaction_promo_detail\n#transaction_df = spark.sql(\"select * from transaction_group order by date_time DESC\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "columns = ['bu_code', 'business_date', 'business_date_key', 'campaign_offer_id', 'card_id', 'transaction_comments',\n           'contact_bu_code', 'contact_id', 'currency_code', 'invoice_number', 'item_amount', 'item_cost', \n           'item_quantity_value', 'item_redeemed_amount', 'item_spread_discount_amount', \n           'item_staff_discount_2_amount', 'item_staff_discount_amount','item_unit_price_amount',\n           'item_vat_amount', 'member_id', 'member_sale_flag', 'member_point_id', \n           'member_voucher_id', 'no_show_card_flag', 'order_number', \n           'payment_amount', 'payment_method_name', 'payment_type_name', 'point_sub_type_name', 'point_type_name',\n           'point_value', 'product_id', 'promotion_discount_amount', 'promotion_id', 'promotion_number',\n           'sale_amount', 'sale_load_date', 'sale_load_key', 'sale_quantity_value', 'sale_redeemed_amount',\n           'sale_staff_discount_2_amount', 'sale_staff_discount_amount', 'store_id', 'transaction_channel_name', \n           'transaction_date', 'transaction_date_key', \n           'transaction_id', 'transaction_type_name', 'voucher_number', 'last_updated_date']\n\nschema = StructType([\n          StructField(\"BU_CODE\", StringType(), nullable = False),\n          StructField(\"BUSINESS_DATE\", StringType(), nullable = True),\n          StructField(\"BUSINESS_DATE_KEY\", StringType(), nullable = True),\n          StructField(\"CAMPAIGN_OFFER_ID\", StringType(), nullable = False),\n          StructField(\"CARD_ID\", StringType(), nullable = True),\n          StructField(\"TRANSACTION_COMMENTS\", StringType(), nullable = True),\n          StructField(\"CONTACT_BU_CODE\", StringType(), nullable = True),\n          StructField(\"CONTACT_ID\", StringType(), nullable = True),\n          StructField(\"CURRENCY_CODE\", StringType(), nullable = True),\n          StructField(\"INVOICE_NUMBER\", StringType(), nullable = True),\n          StructField(\"ITEM_AMOUNT\", StringType(), nullable = True),\n          StructField(\"ITEM_COST\", StringType(), nullable = True),\n          StructField(\"ITEM_QUANTITY_VALUE\", StringType(), nullable = True),\n          StructField(\"ITEM_REDEEMED_AMOUNT\", StringType(), nullable = True),\n          StructField(\"ITEM_SPREAD_DISCOUNT_AMOUNT_\", StringType(), nullable = True),\n          StructField(\"ITEM_STAFF_DISCOUNT_2_AMOUNT\", StringType(), nullable = True),\n          StructField(\"ITEM_STAFF_DISCOUNT_AMOUNT\", StringType(), nullable = True),\n          StructField(\"ITEM_UNIT_PRICE_AMOUNT\", StringType(), nullable = True),\n          StructField(\"ITEM_VAT_AMOUNT\", StringType(), nullable = True),\n          StructField(\"MEMBER_ID\", StringType(), nullable = True),\n          StructField(\"MEMBER_SALE_FLAG\", StringType(), nullable = True),\n          StructField(\"MEMBER_POINT_ID\", StringType(), nullable = True),\n          StructField(\"MEMBER_VOUCHER_ID\", StringType(), nullable = True),\n          StructField(\"NO_SHOW_CARD_FLAG\", StringType(), nullable = True),\n          StructField(\"ORDER_NUMBER\", StringType(), nullable = True),\n          StructField(\"PAYMENT_AMOUNT\", StringType(), nullable = True),\n          StructField(\"PAYMENT_METHOD_NAME\", StringType(), nullable = True),\n          StructField(\"PAYMENT_TYPE_NAME\", StringType(), nullable = True),\n          StructField(\"POINT_SUB_TYPE_NAME\", StringType(), nullable = True),\n          StructField(\"POINT_TYPE_NAME\", StringType(), nullable = True),\n          StructField(\"POINT_VALUE\", StringType(), nullable = True),\n          StructField(\"PRODUCT_ID\", StringType(), nullable = True),\n          StructField(\"PROMOTION_DISCOUNT_AMOUNT\", StringType(), nullable = True),\n          StructField(\"PROMOTION_ID\", StringType(), nullable = False),\n          StructField(\"PROMOTION_NUMBER\", StringType(), nullable = True),\n          StructField(\"SALE_AMOUNT\", StringType(), nullable = True),\n          StructField(\"SALE_LOAD_DATE\", StringType(), nullable = True),\n          StructField(\"SALE_LOAD_DATE_KEY\", StringType(), nullable = True),\n          StructField(\"SALE_QUANTITY_VALUE\", StringType(), nullable = True),\n          StructField(\"SALE_REDEEMED_AMOUNT\", StringType(), nullable = True),\n          StructField(\"SALE_STAFF_DISCOUNT_2_AMOUNT\", StringType(), nullable = True),\n          StructField(\"SALE_STAFF_DISCOUNT_AMOUNT\", StringType(), nullable = True),\n          StructField(\"STORE_ID\", StringType(), nullable = True),\n          StructField(\"TRANSACTION_CHANNEL_NAME\", StringType(), nullable = True),\n          StructField(\"TRANSACTION_DATE\", StringType(), nullable = True),\n          StructField(\"TRANSACTION_DATE_KEY\", StringType(), nullable = True),\n          StructField(\"TRANSACTION_ID\", StringType(), nullable = False),\n          StructField(\"TRANSACTION_TYPE_NAME\", StringType(), nullable = False),\n          StructField(\"VOUCHER_NUMBER\", StringType(), nullable = True),\n          StructField(\"LAST_UPDATED_DATE\", StringType(), nullable = True)\n    ])\n\n# Function to convert to datetime format \ndef parse(date):\n    if date == 'N/A':\n        return date\n    return \"{}-{}-{}\".format(date[:4], date[4:6], date[6:])\n\nudf_parse = udf(parse, StringType())\n\n# Preliminary setup to read from the parquet files for the following tables\ncontainer = \"liyu-output\"\naccount = \"aswstagingsastorage\"\ntables = {\n    # Raw Tables\n    \"WEB_TLOG2\": \"transaction_date\",\n    \"ATLOG_0x01\": \"date\",\n    \"ATLOG_0x03\": \"date\", \n    \"ATLOG_0x04\": \"date\",\n    \"ATLOG_0x05\": \"date\",\n    # RDM Tables\n    \"f_rk_transaction\": \"utc_date_key\",\n    \"f_rk_transaction_detail\": \"utc_date_key\",\n    \"f_rk_transaction_promo_detail\": \"utc_date_key\",\n    \"f_rk_tender\": \"utc_date_key\"\n    }\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 4, "cell_type": "code", "source": "# Need this dataframe in order create the join by utc_date_key \ntry:\n    date_df = spark.read.parquet(\"wasbs://%s@%s.blob.core.windows.net/phase2_output/%s/D_RK_DATE.parquet/\" \n                                  % (container, account, end_id)).select(\"date_key\", \"compact_date\")\nexcept AnalysisException:\n    print(\"Did not read parquet\")\n    raise\n    \nfirst_table = True\nmerge_df = None\nfor table_value in tables:\n    df = None\n    group_col = tables[table_value]\n    # Read from parquet for the range in the runids and union the dataframes \n    for runid in range(start_id, end_id + 1):\n        try: \n            if table_value == \"WEB_TLOG2\":\n                input_df = spark.read.parquet(\"wasbs://%s@%s.blob.core.windows.net/phase1_output/%s/WEB_TLOG2.parquet/\" \n                                              % (container, account, \n                                                 runid)).select(group_col)\n                \n            elif table_value.startswith('ATLOG'):\n                input_df = spark.read.parquet(\"wasbs://%s@%s.blob.core.windows.net/phase1_output/%s/ATLOG.parquet/%s/\" \n                                              % (container, account, runid, \n                                                 table_value)).select(group_col)\n            else:\n                input_df = spark.read.parquet(\"wasbs://%s@%s.blob.core.windows.net/phase2_output/%s/%s.parquet/\"\n                                              % (container, account, runid, \n                                                 table_value.upper())).select(group_col)\n            if df is None:\n                df = input_df\n\n            else:\n                df = df.union(input_df)\n        except AnalysisException:\n            print(runid, table_value)\n            # means the runid does not have the table\n            pass\n    \n    # group by date and cast as datetime object    \n    if table_value.startswith('ATLOG'):\n        df = df.withColumn(group_col, udf_parse(group_col))\n        \n    elif table_value.startswith('f_rk'):\n        df = df.join(date_df, df.utc_date_key == date_df.date_key, how='left')\n        df = df.withColumn(group_col, udf_parse('compact_date'))\n        \n    df = df.selectExpr('cast(%s as date) as date_time' % group_col)\n    df = df.groupby('date_time').count()\n    df = df.selectExpr('date_time', 'count as %s' % table_value)\n\n    if first_table:\n        first_table = False\n        merge_df = df\n    else:\n        merge_df = merge_df.join(df, on=['date_time'], how='outer')\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "100813 WEB_TLOG2\n100817 ATLOG_0x05\n100817 ATLOG_0x04\n100817 ATLOG_0x03\n100817 ATLOG_0x01"}], "metadata": {"collapsed": false}}, {"execution_count": 25, "cell_type": "code", "source": "unique_stores = spark.sql(\"\"\"\nselect d.compact_date, count(distinct s.store_id) as store_count from f_rk_transaction as t\nleft join d_rk_date as d\non t.utc_date_key=d.date_key\nleft join d_rk_store as s\non t.store_key=s.store_key\ngroup by d.compact_date\norder by d.compact_date DESC\nlimit 1000\n\"\"\")\n\nunique_stores = unique_stores.na.drop().withColumn(\n    'parsed_date', udf_parse('compact_date')).selectExpr('cast(parsed_date as date)', 'store_count')\n\n#unique_stores.show()\n\ntransaction_df = merge_df.join(unique_stores, [merge_df.date_time == unique_stores.parsed_date], 'left')\ntransaction_df = transaction_df.orderBy('date_time', ascending=False).fillna(0)\n\ntransaction_df = transaction_df.selectExpr('date_time', \"WEB_TLOG2\", \"ATLOG_0X01 as x01\", \n                                           \"f_rk_transaction_detail as transaction_detail\",\n                                           \"ATLOG_0x03 as x03\", \"f_rk_transaction_promo_detail as promo_detail\",\n                                           \"ATLOG_0x04 as x04\", \"f_rk_tender as tender\",\n                                           \"ATLOG_0x05 as x05\", \"f_rk_transaction as transaction\",\n                                           \"store_count\")\n\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 26, "cell_type": "code", "source": "# Last 7 RunIds\ntransaction_df.show(100)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+---------+------+------------------+-------+------------+------+------+------+-----------+-----------+\n| date_time|WEB_TLOG2|   x01|transaction_detail|    x03|promo_detail|   x04|tender|   x05|transaction|store_count|\n+----------+---------+------+------------------+-------+------------+------+------+------+-----------+-----------+\n|2018-04-09|      555|    33|                 0|     71|           0|    19|     0|    10|          0|          0|\n|2018-04-08|     1596|292321|            248917| 555514|      304000|194295|191255|108871|     107174|          0|\n|2018-04-07|     7834|938334|            785322|2346321|     1383711|623638|621221|280209|     279211|          0|\n|2018-04-06|     1569|466995|            198464| 883463|      496277|310821|313177|177005|      85707|          0|\n|2018-04-05|     1555|585628|            265934|1181955|      671519|361287|361336|206526|     108767|          0|\n|2018-04-04|     1365|576986|            495353|1117383|      629911|357709|358010|205772|     204457|          0|\n|2018-04-03|     4626|479208|            416216| 933107|      519124|306353|307205|176326|     176718|          0|\n|2018-04-02|     9013|470038|            408891| 911719|      498057|312242|312871|175264|     175534|          0|\n|2018-04-01|     9507|277272|            246486| 534614|      300900|173494|176912| 98624|     100676|          0|\n|2018-03-31|    14975| 19852|             19964|  54137|       31372| 10657| 11721|  4345|       4902|          0|\n|2018-03-30|    10040|  5726|              8347|  16432|       16455|  3132|  4844|  1291|       2264|          0|\n|2018-03-29|     5602|  6642|              9237|  17704|       15275|  2940|  4194|  1248|       2147|          0|\n|2018-03-28|     1124|  1252|              2789|   2091|        4694|   503|  1281|   350|        930|          0|\n|2018-03-27|      516|   579|               878|    818|         953|   217|   399|   167|        309|          0|\n|2018-03-26|      446|   347|               473|    532|         494|   132|   197|    92|        152|          0|\n|2018-03-25|      363|   215|               345|    303|         355|    76|   136|    59|        118|          0|\n|2018-03-24|      614|   531|               572|   1524|         829|   285|   306|   129|        161|          0|\n|2018-03-23|       87|   103|               339|    379|         622|    52|   146|    27|        100|          0|\n|2018-03-22|       32|    42|                62|     28|          53|     7|    20|     7|         19|          0|\n|2018-03-21|        8|     2|                11|      8|          15|     2|     8|     1|          7|          0|\n|2018-03-20|        5|     0|                 2|      0|           4|     0|     1|     0|          1|          0|\n|2018-03-19|        0|     0|                 1|      0|           2|     0|     1|     0|          1|          0|\n|2018-03-18|        0|     3|                 3|      0|           0|     6|     6|     3|          3|          0|\n|2018-03-17|        4|     6|                 6|      6|           3|     2|     2|     1|          1|          0|\n|2018-03-16|       24|     0|                 1|      0|           1|     0|     1|     0|          1|          0|\n|2018-03-15|        0|     5|                 8|      0|          15|     6|     3|     3|          2|        448|\n|2018-03-14|        8|     0|                 4|      0|           0|     0|     4|     0|          2|        462|\n|2018-03-13|      254|     0|                 2|      0|           4|     0|     1|     0|          1|         38|\n|2018-03-12|      523|     0|                 1|      0|           3|     0|    34|     0|          1|          4|\n|2018-03-11|        0|     0|                 1|      0|           3|     0|    68|     0|          1|          5|\n|2018-03-10|        5|     0|                 0|      0|           0|     0|     0|     0|          0|          6|\n|2018-03-09|        4|     0|                 1|      0|           2|     0|     1|     0|          1|          5|\n|2018-03-08|        0|     2|                 3|      4|           3|     1|     2|     1|          2|          5|\n|2018-03-04|        0| 61346|                 0| 137362|       66499| 40312| 37723| 22863|          0|          5|\n|2018-03-03|        0|454097|                 0|1137427|      584989|280446|279226|150452|          0|          2|\n|2018-03-02|        0|274743|                 5| 624933|      323135|179254|179967| 99701|          1|          4|\n|2018-03-01|        0|241037|                 0| 546903|      284704|155064|157106| 86470|          0|          0|\n|2018-02-28|        0|  2626|                 0|   5234|        4466|  1813|  2767|   800|          0|          1|\n|2018-02-27|        0|   698|                 0|   1475|         756|   373|   447|   196|          0|          0|\n|2018-02-26|        0| 49215|                 0| 113419|       55086| 38776| 36826| 19620|          0|          1|\n|2018-02-25|        0|380582|                95| 963889|      516982|275292|272337|128553|         40|          1|\n|2018-02-24|      920|606543|                24|1659848|      903502|406523|405413|184889|         11|          2|\n|2018-02-23|     1352|297623|                 1| 687428|      362704|216551|219804|107785|          1|          2|\n|2018-02-22|     3411|187338|                 0| 428350|      227250|133740|135910| 66185|          0|          1|\n|2018-02-21|     2498|  3000|                 0|   5992|        6247|  1667|  2729|   967|          0|          0|\n|2018-02-20|     1308| 61611|                 0| 139101|       69901| 43991| 41663| 22182|          0|          1|\n|2018-02-19|      939|318963|                 0| 725861|      379079|231485|230500|115396|          0|          0|\n|2018-02-18|     1261|325764|                 0| 746778|      390016|237209|237426|118660|          0|          0|\n|2018-02-17|      734|340463|                 0| 862250|      451013|241699|241454|118316|          0|          0|\n|2018-02-16|      581|310555|                 0| 724183|      382577|223591|224696|111528|          0|          0|\n|2018-02-15|      402|326430|                 0| 775507|      404990|233863|232884|114019|          0|          0|\n|2018-02-14|      703|318093|                 0| 792442|      414268|235251|237258|113903|          0|          0|\n|2018-02-13|     3569|  3616|                 0|   7930|        6014|  2299|  3809|  1206|          0|          0|\n|2018-02-12|     5263|  1241|                 0|   2261|        2774|   542|   964|   299|          0|          0|\n|2018-02-11|     2340|  3197|                 0|   7888|        5825|  1634|  2060|   656|          0|          0|\n|2018-02-10|     4883|  5387|                 0|  13680|        7820|  2727|  2982|  1087|          0|        236|\n|2018-02-09|     2032|  1004|                 0|   2421|        4295|   415|  1385|   232|          0|        189|\n|2018-02-08|     3488|   337|                 0|    505|        1221|   112|   379|    72|          0|        266|\n|2018-02-07|     4540|    99|                 0|    201|        1822|    62|   416|    24|          0|        244|\n|2018-02-06|     4281|    82|                 0|    150|        2414|    41|   512|    19|          0|         72|\n|2018-02-05|     1971|    51|                 0|    119|        2210|    17|   489|    13|          0|        335|\n|2018-02-04|     2810|    33|                 0|     46|         927|     9|   262|     7|          0|        538|\n|2018-02-03|     3189|   151|                 0|    422|        1419|    71|   409|    29|          0|        533|\n|2018-02-02|      740|     7|                 0|     10|        1631|     2|   372|     1|          0|        546|\n|2018-02-01|      220|     6|                 0|      4|         286|     1|   122|     1|          0|        540|\n|2018-01-31|      225|     0|                 0|      0|          83|     0|    32|     0|          0|        465|\n|2018-01-30|      144|     0|                 0|      0|          94|     0|    35|     0|          0|        548|\n|2018-01-29|       84|     3|                 0|      0|          59|     2|    22|     1|          0|        526|\n|2018-01-28|       59|     0|                 0|      0|          34|     0|    14|     0|          0|        561|\n|2018-01-27|       20|     0|                 0|      0|          26|     0|     7|     0|          0|        562|\n|2018-01-26|       11|     0|                 0|      0|           7|     0|     4|     0|          0|        561|\n|2018-01-25|        0|     8|                 0|     19|          14|     5|     5|     3|          0|        562|\n|2018-01-24|       16|     6|                 0|      8|           1|     2|     1|     2|          0|        562|\n|2018-01-23|       20|     2|                 0|      6|          14|     2|     6|     1|          0|        561|\n|2018-01-22|        4|     0|                 0|      0|           8|     0|     2|     0|          0|        562|\n|2018-01-21|        0|     0|                 0|      0|           1|     0|     1|     0|          0|        561|\n|2018-01-16|        5|     0|                 0|      0|           0|     0|     0|     0|          0|        562|\n|2018-01-15|        0|     0|                 0|      0|           2|     0|     1|     0|          0|        562|\n|2018-01-11|        0|     2|                 0|      6|           3|     2|     2|     1|          0|        560|\n|2018-01-08|        0|     3|                 0|      9|           4|     2|     2|     1|          0|        558|\n|2017-12-30|        0|     5|                 0|     16|           0|     2|     0|     1|          0|        560|\n|2017-12-29|        0|     0|                 0|      0|           7|     0|     2|     0|          0|        560|\n|2017-12-10|        0|     9|                 0|     37|          18|     3|     3|     1|          0|        553|\n+----------+---------+------+------------------+-------+------------+------+------+------+-----------+-----------+"}], "metadata": {"collapsed": false}}, {"execution_count": 5, "cell_type": "code", "source": "# Raw table\ntlog2_05_path = \"wasbs://liyu@aswprodsastorage.blob.core.windows.net/ASW/WTCTW/raw/RTLOG/WEB_TLOG2/2018/04/05/*csv.gz\"\ntlog2_06_path = \"wasbs://liyu@aswprodsastorage.blob.core.windows.net/ASW/WTCTW/raw/RTLOG/WEB_TLOG2/2018/04/06/*csv.gz\"\n\nweb_tlog2_05 = spark.read.csv(tlog2_05_path, schema=schema)\nweb_tlog2_06 = spark.read.csv(tlog2_06_path, schema=schema)\n\n# RDM tables\ntransaction_812 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100812/F_RK_TRANSACTION.parquet/\"\ntransaction_813 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100813/F_RK_TRANSACTION.parquet/\"\npromo_detail_812 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100812/F_RK_TRANSACTION_PROMO_DETAIL.parquet/\"\npromo_detail_813 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100813/F_RK_TRANSACTION_PROMO_DETAIL.parquet/\"\ntransaction_detail_812 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100812/F_RK_TRANSACTION_DETAIL.parquet/\"\ntransaction_detail_813 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100813/F_RK_TRANSACTION_DETAIL.parquet/\"\ntender_812 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100812/F_RK_TENDER.parquet/\"\ntender_813 = \"wasbs://liyu-output@aswstagingsastorage.blob.core.windows.net/phase2_output/100813/F_RK_TENDER.parquet/\"\n\n# tables that were rerun from p2_out_retry9 from liyu-output \nretry_transaction_813 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100813/f_rk_transaction.parquet/\"\nretry_transaction_815 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100815/f_rk_transaction.parquet/\"\nretry_promo_detail_813 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100813/f_rk_transaction_promo_detail.parquet/\"\nretry_promo_detail_815 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100815/f_rk_transaction_promo_detail.parquet/\"\nretry_transaction_detail_813 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100813/f_rk_transaction_detail.parquet/\"\nretry_transaction_detail_815 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100815/f_rk_transaction_detail.parquet/\"\nretry_tender_813 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100813/f_rk_tender.parquet/\"\nretry_tender_815 = \"wasbs://devliyu@devincrloadingeastus.blob.core.windows.net/k_chan/100815/f_rk_tender.parquet/\"\n\n\ndef remove_str(id_val):\n    if id_val[:6] == \"WTCTW_\":\n        return id_val[6:]\n    return id_val\n\ndef remove_salt_str(id_val):\n    if id_val[3:10] == \"_WTCTW_\":\n        return id_val[10:]\n    return id_val\n\n# For promo_detail\ndef append_promo_remove_str(ids):\n    promo_id = ids[0]\n    detail_id = ids[1]\n    if detail_id[:6] == \"WTCTW_\":\n        return detail_id[6:] + '_' + promo_id\n    return '_' + promo_id\n\nudf_remove_salt_str = udf(remove_salt_str, StringType())\nudf_remove_str = udf(remove_str, StringType())\nudf_append_promo_remove_str = udf(append_promo_remove_str, StringType())\n\nweb_tlog2_05.createOrReplaceTempView(\"web_tlog2_05\")\nweb_tlog2_06.createOrReplaceTempView(\"web_tlog2_06\")\n\ntables = { \"f_rk_transaction\" : [transaction_812, transaction_813],\n           \"f_rk_promo_detail\" : [promo_detail_812, promo_detail_813],\n           \"f_rk_transaction_detail\": [transaction_detail_812, transaction_detail_813],\n           \"f_rk_tender\" : [tender_812, tender_813]\n         }\n\nweb_tlog2_store_ids = ['987', '970', '953', '952', '988', '962']\nmissing_data = None\n\nfor table in tables:\n    for path in tables[table]:\n        raw_data = None\n        parse_rdm = None\n        ingested_data = None\n        if \"100812\" in path:\n            raw_table = \"web_tlog2_05\"\n            run_id = '100812'\n            transaction_path = transaction_812\n        else:\n            raw_table = \"web_tlog2_06\"\n            run_id = '100813'\n            transaction_path = transaction_813\n    \n        rdm_data = spark.read.parquet(path)\n        \n        # Each table shares similar logic. Majority consist of inner joinining on the parsed transaction_id\n        if table == \"f_rk_transaction\":\n            raw_data = spark.sql('''\n            select transaction_id, store_id\n            from %s\n            where transaction_type_name == 'Sale'\n            ''' % raw_table)\n\n            parse_rdm = rdm_data.selectExpr('cast(transaction_id as string) as rdm_id').withColumn(\n                'parsed_id', udf_remove_str('rdm_id'))\n\n            ingested_data = parse_rdm.join(raw_data, [raw_data.transaction_id == parse_rdm.parsed_id], 'inner')\n        \n        elif table == \"f_rk_promo_detail\":\n            raw_data = spark.sql('''\n            select transaction_id, store_id\n            from %s\n            where transaction_type_name == 'Promotion'\n            ''' % raw_table)\n            \n            promo_detail = rdm_data            \n            promo_detail.createOrReplaceTempView('promo_detail')\n            \n            # To get the promo id to build the parsed transaction_id\n            joined_rdm_data = spark.sql('''\n            select d_adm_promo.promo_id, promo_detail.transaction_detail_id from promo_detail\n                left join d_adm_promo on\n                promo_detail.promo_key == d_adm_promo.promo_key\n            ''').na.fill(0)\n            \n            parsed_rdm = joined_rdm_data.withColumn('parsed_id', udf_append_promo_remove_str(\n                    array('promo_id', 'transaction_detail_id')))\n            \n            # join the parsed id with the transaction_id from raw data\n            ingested_data = parsed_rdm.join(raw_data, [raw_data.transaction_id == parsed_rdm.parsed_id], 'inner')\n            \n        elif table == \"f_rk_transaction_detail\":\n            raw_data = spark.sql('''\n            select transaction_id, store_id\n            from %s\n            where transaction_type_name == 'Item'\n            ''' % raw_table)\n            \n            parse_rdm = rdm_data.selectExpr('cast(transaction_detail_id as string) as rdm_id').withColumn(\n                'parsed_id', udf_remove_salt_str('rdm_id'))\n            \n            ingested_data = parse_rdm.join(raw_data, [raw_data.transaction_id == parse_rdm.parsed_id], 'inner')\n        \n        else:\n            raw_data = spark.sql('''\n            select order_number, store_id\n            from %s\n            where transaction_type_name == 'Tender'\n            ''' % raw_table)\n            \n            f_rk_transaction_data = spark.read.parquet(transaction_path)\n            # Join with f_rk_transaction to get the rdm transaction_id to inner join with the raw transaction_id\n            tender_data = rdm_data.selectExpr('transaction_key as tender_key', 'tender_method_name', 'tender_detail_name')\n            tender_data = f_rk_transaction_data.join(tender_data, [tender_data.tender_key == \n                                                             f_rk_transaction_data.TRANSACTION_KEY], 'inner')\n            parse_rdm = tender_data.withColumn('parsed_id', udf_remove_str('TRANSACTION_ID'))\n            \n            ingested_data = parse_rdm.join(raw_data, [parse_rdm.parsed_id == raw_data.order_number],\n                                          'inner')\n            \n        raw_store_count = raw_data.groupBy('store_id').count()\n        rdm_data.createOrReplaceTempView('rdm_data')\n        rdm_store_count = spark.sql('''select store_id as rdm_store_ids, count(store_id) as rdm_count\n        from d_rk_store\n        inner join rdm_data \n        on d_rk_store.store_key == rdm_data.store_key\n        group by d_rk_store.store_id\n        ''')\n        \n        rdm_store_count = rdm_store_count.filter(rdm_store_count.rdm_store_ids.isin(web_tlog2_store_ids))\n        \n        print(table + ' ' + run_id)\n        print(\"Unique Values: \" + str(ingested_data.select('parsed_id').distinct().count()))\n        print('Row Count of RDM Data Merged: ' + str(ingested_data.count()))\n        print('Row Count of Raw Data: ' + str(raw_data.count()))\n        print('==============')\n        print('Raw and RDM Store_id Count')\n        raw_store_count.join(rdm_store_count, [rdm_store_count.rdm_store_ids == raw_store_count.store_id], \n                          'outer').selectExpr('store_id', 'count as raw_count', 'rdm_count').show()\n        print('==============')", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f_rk_promo_detail 100812\nUnique Values: 3636\nRow Count of RDM Data Merged: 3636\nRow Count of Raw Data: 3636\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|     1482|     1482|\n|     970|      528|      528|\n|     953|      515|      515|\n|     988|     1111|     1111|\n+--------+---------+---------+\n\n==============\nf_rk_promo_detail 100813\nUnique Values: 0\nRow Count of RDM Data Merged: 0\nRow Count of Raw Data: 3306\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|        2|     null|\n|     970|      226|     null|\n|     953|      398|     null|\n|     952|      477|     null|\n|     988|     2203|     null|\n+--------+---------+---------+\n\n==============\nf_rk_transaction_detail 100812\nUnique Values: 1847\nRow Count of RDM Data Merged: 1847\nRow Count of Raw Data: 1847\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|      765|      765|\n|     970|      246|      246|\n|     953|      317|      317|\n|     988|      519|      519|\n+--------+---------+---------+\n\n==============\nf_rk_transaction_detail 100813\nUnique Values: 0\nRow Count of RDM Data Merged: 0\nRow Count of Raw Data: 1708\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|        2|     null|\n|     970|       97|     null|\n|     953|      246|     null|\n|     952|      298|     null|\n|     988|     1065|     null|\n+--------+---------+---------+\n\n==============\nf_rk_tender 100812\nUnique Values: 743\nRow Count of RDM Data Merged: 743\nRow Count of Raw Data: 743\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|      294|      294|\n|     970|      102|      102|\n|     953|      164|      164|\n|     988|      183|      183|\n+--------+---------+---------+\n\n==============\nf_rk_tender 100813\nUnique Values: 0\nRow Count of RDM Data Merged: 0\nRow Count of Raw Data: 716\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|        1|     null|\n|     970|       48|     null|\n|     953|      140|     null|\n|     952|      111|     null|\n|     988|      416|     null|\n+--------+---------+---------+\n\n==============\nf_rk_transaction 100812\nUnique Values: 743\nRow Count of RDM Data Merged: 743\nRow Count of Raw Data: 743\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|      294|      294|\n|     970|      102|      102|\n|     953|      164|      164|\n|     988|      183|      183|\n+--------+---------+---------+\n\n==============\nf_rk_transaction 100813\nUnique Values: 0\nRow Count of RDM Data Merged: 0\nRow Count of Raw Data: 716\n==============\nRaw and RDM Store_id Count\n+--------+---------+---------+\n|store_id|raw_count|rdm_count|\n+--------+---------+---------+\n|     987|        1|     null|\n|     970|       48|     null|\n|     953|      140|     null|\n|     952|      111|     null|\n|     988|      416|     null|\n+--------+---------+---------+\n\n=============="}], "metadata": {"scrolled": true, "collapsed": false}}, {"source": "As it stands the data from web_tlog_05 was all ingested, where nothing from web_tlog_06 was found in rdm.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}